% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/iRF.R
\name{iRF}
\alias{iRF}
\title{iterative Random Forest}
\usage{
iRF(
  x,
  y,
  ntree = 500,
  iter = 5,
  classification = F,
  threads = 1,
  alwayssplits = NULL,
  mtry = NULL,
  saveall = T
)
}
\arguments{
\item{x}{feature matrix (i.e. the predictors for random forest)}

\item{y}{the dependent variable (i.e. the variable being predicted)}

\item{ntree}{number of trees in the random forest}

\item{iter}{number of iterations to run}

\item{classification}{boolean. If FALSE, then use Regression RF. Default = FALSE}

\item{threads}{default = 1}

\item{alwayssplits}{Character vector with variable names to be always selected in addition to the mtry variables tried for splitting.}

\item{mtry}{Number of variables to possibly split at in each node.
Default is the (rounded down) square root of the number variables with importance > 0.
If 0 < mtry < 1, then it will be treated as a proportion of variables with importance > 0.
Otherwise it is the absolute number of variables to use when splitting a node.}

\item{saveall}{if TRUE then return the final random forest from each iteration as a list of forests}
}
\value{
if saveall=TRUE, returns a list of random forest objects. Otherwise one random forest object
from the iteration that had the best model fit.
}
\description{
iterative Random Forest
}
\examples{

iRF(x = xmat, y = yvec, saveall=TRUE)

}
